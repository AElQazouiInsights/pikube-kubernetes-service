import{_ as r,c as a,j as n,a as o,t as i,a0 as s,o as l}from"./chunks/framework.pWuaoOf3.js";const f=JSON.parse('{"title":"Kubernetes Networking Fundamentals","description":"","frontmatter":{"title":"Kubernetes Networking Fundamentals","permalink":"/docs/13-reference-docs/kubernetes-networking-fundamentals"},"headers":[],"relativePath":"13-further-reading/kubernetes-networking-fundamentals.md","filePath":"13-further-reading/kubernetes-networking-fundamentals.md"}'),d={name:"13-further-reading/kubernetes-networking-fundamentals.md"},c={id:"frontmatter-title",tabindex:"-1"};function p(t,e,u,h,b,g){return l(),a("div",null,[n("h1",c,[o(i(t.$frontmatter.title)+" ",1),e[0]||(e[0]=n("a",{class:"header-anchor",href:"#frontmatter-title","aria-label":'Permalink to "{{ $frontmatter.title }}"'},"​",-1))]),e[1]||(e[1]=s('<h2 id="enabling-inter-pod-and-pod-to-pod-communication-across-nodes-cni" tabindex="-1">Enabling Inter-Pod and Pod-to-Pod Communication Across Nodes (CNI) <a class="header-anchor" href="#enabling-inter-pod-and-pod-to-pod-communication-across-nodes-cni" aria-label="Permalink to &quot;Enabling Inter-Pod and Pod-to-Pod Communication Across Nodes (CNI)&quot;">​</a></h2><p>Kubernetes itself does not provide built-in functionality for containers to communicate across different nodes. Instead, it operates under the assumption that each container (pod) has a unique, routable IP address within the cluster. To enable communication between containers across different nodes, networking solutions based on Pure Layer-3, VxLAN, or UDP models can be implemented.</p><p>The Container Network Interface (CNI) plugin system is essential for enabling this cross-node communication. Flannel represents one such solution, providing an overlay network that can operate using either UDP or VxLAN-based models.</p><p>The CNI plugin has several key responsibilities. It must insert a network interface into the container network namespace (for example, one end of a virtual ethernet (veth) pair) and make any necessary modifications on the host (such as attaching the other end of the veth into a bridge). Additionally, the plugin assigns IP addresses to interfaces and configures routes according to the IP Address Management section by calling the appropriate IP Address Management (IPAM) plugin.</p><h2 id="enabling-kubernetes-services-load-balancing" tabindex="-1">Enabling Kubernetes Services Load Balancing <a class="header-anchor" href="#enabling-kubernetes-services-load-balancing" aria-label="Permalink to &quot;Enabling Kubernetes Services Load Balancing&quot;">​</a></h2><p>In Kubernetes, a Service provides an abstract method for exposing applications running on a set of Pods as a network service. Kubernetes assigns individual IP addresses to Pods and provides a single DNS name (and single Virtual IP address) for a set of Pods, enabling load-balancing across them. This functionality relies on two critical components:</p><ol><li><code>kube-proxy</code>: Responsible for implementing the Virtual IP address and load balancing mechanism</li><li><code>kube-dns</code>: Handles the mapping of DNS service names to virtual IP addresses</li></ol><p>For a deeper understanding, refer to the <a href="https://kubernetes.io/docs/concepts/services-networking/service/" target="_blank" rel="noreferrer">Kubernetes documentation on Service Concepts</a>.</p><h3 id="kube-proxy-kubernetes-services-internal-load-balancing" tabindex="-1">kube-proxy: Kubernetes Services Internal Load-balancing <a class="header-anchor" href="#kube-proxy-kubernetes-services-internal-load-balancing" aria-label="Permalink to &quot;kube-proxy: Kubernetes Services Internal Load-balancing&quot;">​</a></h3><p>The kube-proxy component plays a vital role in any Kubernetes deployment. Its primary function is to load-balance traffic directed at services (through Cluster IPs and Node Ports) to the appropriate backend pods.</p><p>Kube-proxy can operate in three distinct modes, each implemented using different data plane technologies:</p><ol><li>User-space mode (legacy implementation, no longer commonly used)</li><li>Iptables proxy mode (default since Kubernetes v1.2)</li><li>IPVS mode (introduced in Kubernetes v1.8, GA in v1.11)</li></ol><p>Both iptables and IPVS modes utilize the operating system&#39;s packet filtering layer (<code>netfilter</code>).</p><p>In iptables mode, kube-proxy monitors the Kubernetes control plane for changes in Service and Endpoint objects. For each Service, it creates iptables rules that capture traffic to the Service&#39;s clusterIP and port, redirecting that traffic to one of the Service&#39;s backend sets. For each Endpoint object, it establishes iptables rules to select a backend Pod.</p><p>By default, when operating in iptables mode, kube-proxy selects backends randomly. For more detailed information about IPVS functionality, consult the <a href="https://github.com/kubernetes/kubernetes/blob/master/pkg/proxy/ipvs/README.md" target="_blank" rel="noreferrer">IPVS documentation</a>.</p><p>To summarize the process:</p><ol><li>A service represents a collection of pods, each with their own IP address (e.g., 10.1.0.3, 10.2.3.5, 10.3.5.6)</li><li>Every Kubernetes service receives an IP address (e.g., 10.23.1.2)</li><li>The CNI plugin manages POD address allocation and ensures pod routability</li><li>kube-dns resolves Kubernetes service DNS names to IP addresses (mapping something like my-svc.my-namespace.svc.cluster.local to 10.23.1.2)</li><li>kube-proxy configures iptables rules for random load balancing between pods</li></ol><p>When a request is made to my-svc.my-namespace.svc.cluster.local, it resolves to 10.23.1.2, and then iptables rules on the node (created by kube-proxy) randomly redirect it to one of the backend pod IPs (10.1.0.3, 10.2.3.5, or 10.3.5.6).</p><h2 id="routing-incoming-http-https-traffic" tabindex="-1">Routing Incoming HTTP/HTTPS Traffic <a class="header-anchor" href="#routing-incoming-http-https-traffic" aria-label="Permalink to &quot;Routing Incoming HTTP/HTTPS Traffic&quot;">​</a></h2><p>The Ingress resource in Kubernetes exposes HTTP and HTTPS routes from outside the cluster to services within it. Traffic routing is controlled by rules defined in the Ingress resource.</p><p>An Ingress can be configured to:</p><ul><li>Provide services with externally-reachable URLs</li><li>Load balance traffic</li><li>Terminate SSL/TLS connections</li><li>Offer name-based virtual hosting</li></ul><p>The Ingress Controller component is responsible for implementing the Ingress rules. It typically needs to be deployed within the cluster, usually with an external load balancer to handle incoming traffic.</p><p>Every Ingress resource belongs to an IngressClass resource that contains information about the Ingress Controller implementing the class. This design allows different controllers to implement different Ingresses.</p><p>For comprehensive information, consult the <a href="https://kubernetes.io/docs/concepts/services-networking/ingress/" target="_blank" rel="noreferrer">Kubernetes documentation on Ingress Controller Concepts</a>.</p><h2 id="further-reading" tabindex="-1">Further Reading <a class="header-anchor" href="#further-reading" aria-label="Permalink to &quot;Further Reading&quot;">​</a></h2><p>For those interested in diving deeper into Kubernetes networking concepts, here are some valuable resources:</p><ol><li><a href="https://blog.mbrt.dev/posts/container-network/" target="_blank" rel="noreferrer">Understanding Container Networking</a></li><li><a href="https://more.suse.com/rs/937-DCH-261/images/Diving-Deep-Into-Kubernetes-Networking.pdf" target="_blank" rel="noreferrer">Deep Dive into Kubernetes Networking (Rancher Whitepaper)</a></li><li><a href="https://ronaknathani.com/blog/2020/08/how-a-kubernetes-pod-gets-an-ip-address/" target="_blank" rel="noreferrer">Pod IP Address Allocation Process</a></li><li><a href="https://github.com/containernetworking/cni" target="_blank" rel="noreferrer">CNI GitHub Repository</a></li><li><a href="https://msazure.club/flannel-networking-demystify/" target="_blank" rel="noreferrer">Understanding Flannel Networking</a></li><li><a href="https://ilearnedhowto.wordpress.com/2017/02/16/how-to-create-overlay-networks-using-linux-bridges-and-vxlans/" target="_blank" rel="noreferrer">Creating Overlay Networks with Linux Bridges and VXLANs</a></li></ol>',28))])}const k=r(d,[["render",p]]);export{f as __pageData,k as default};
